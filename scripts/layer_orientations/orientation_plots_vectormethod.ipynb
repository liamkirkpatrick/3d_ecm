{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make plots of layer orientation\n",
    "\n",
    "Requires master_orientation.py has already been run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# math\n",
    "from statsmodels.stats.weightstats import DescrStatsW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_angles = '../../data/angles/'\n",
    "path_to_figures = '../../../figures/paper_figures/'\n",
    "\n",
    "# set path to final figure\n",
    "path_to_final_fig = '../../../final_submission/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Angle Data\n",
    "\n",
    "Requires that master_orientation.py has already been run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alhic2302 = pd.read_pickle(path_to_angles+'alhic2302_angles.df')\n",
    "alhic2201 = pd.read_pickle(path_to_angles+'alhic2201_angles.df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust Aparent Dip for geometry\n",
    "\n",
    "All aparent dip is calculated in the same reference frame. However, we need to flip one of the two faces for both cores to achieve our definition of a positive dip as sloping down from the center of the core. This means flipping 't' on ALHIC2201 and 'l' on ALHIC2302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply all angles in 'AC-l-angles' by -1 in alhic2302\n",
    "for index,row in alhic2302.iterrows():\n",
    "    alhic2302.at[index,'AC-l-angles'] = list(map(lambda x: x * -1, row['AC-l-angles']))\n",
    "\n",
    "# multiply all angles in 'AC-t-angles' by -1 in alhic2201\n",
    "for index,row in alhic2201.iterrows():\n",
    "    alhic2201.at[index,'AC-t-angles'] = list(map(lambda x: x * -1, row['AC-t-angles']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate True Angle Orientations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to calculate true dip, dip direction, and score\n",
    "\n",
    "def calc_dip(df,face):\n",
    "\n",
    "    dip = []\n",
    "    dip_direction = []\n",
    "    dip_score = []\n",
    "    for index,row in df.iterrows():\n",
    "\n",
    "        # pull out values from the side (first check there are three)\n",
    "        if row['AC-'+face+'-angles'] != None and len(row['AC-'+face+'-angles']) > 2:\n",
    "            add_nan = False\n",
    "            side_angle = np.array(row['AC-'+face+'-angles']) * np.pi/180\n",
    "            side_score = np.array(row['AC-'+face+'-scores'])\n",
    "            side_length = np.array(row['AC-'+face+'-length'])\n",
    "        else:\n",
    "            add_nan = True\n",
    "\n",
    "        # pull out values from the top\n",
    "        if row['AC-t-angles'] != None and len(row['AC-t-angles']) > 2:\n",
    "            top_angle = np.array(row['AC-t-angles']) * np.pi/180\n",
    "            top_score = np.array(row['AC-t-scores'])\n",
    "            top_length = np.array(row['AC-t-length'])\n",
    "        else:\n",
    "            add_nan = True\n",
    "        \n",
    "\n",
    "        # set true angle to nan if we don't have enough data\n",
    "        if add_nan:\n",
    "            dip_score_ind = [np.nan]\n",
    "            dip_dir_ind = [np.nan]\n",
    "            dip_ind = [np.nan]\n",
    "        \n",
    "        # else, calculate dip and save to list\n",
    "        else:\n",
    "\n",
    "            # assign delta 1 and delta 2\n",
    "            if face == 'l':\n",
    "                d1 = top_angle\n",
    "                d2 = side_angle\n",
    "                \n",
    "                d1_score = top_score * top_length\n",
    "                d2_score = side_score * side_length\n",
    "                \n",
    "            elif face == 'r':\n",
    "                \n",
    "                d1 = side_angle\n",
    "                d2 = top_angle\n",
    "\n",
    "                d1_score = side_score * side_length\n",
    "                d2_score = top_score * top_length\n",
    "            else:\n",
    "                print('Error: face must be either t or l')\n",
    "                break\n",
    "\n",
    "            # make empty lists\n",
    "            dip_score_ind = []\n",
    "            dip_dir_ind = []\n",
    "            dip_ind = []\n",
    "\n",
    "            for i in range(len(d2)):\n",
    "                for j in range(len(d1)):\n",
    "\n",
    "                    # calculate dip score\n",
    "                    ds = d1_score[j] * d2_score[i]\n",
    "                    dip_score_ind.append(ds)\n",
    "\n",
    "                    # calculate dip direction\n",
    "                    dd = np.arctan(np.tan(d2[i])/np.tan(d1[j])) \n",
    "                    \n",
    "\n",
    "                    # calculate true dip\n",
    "                    d = np.arctan(np.tan(d1[j])/np.cos(dd))\n",
    "                    \n",
    "                    # now deal with cases where the dip is negative\n",
    "                    if d<0:\n",
    "                        d = d*-1\n",
    "                        dd = dd + np.pi\n",
    "                        #dd = dd * -1\n",
    "                    \n",
    "                    # store values\n",
    "                    dip_dir_ind.append(dd* 180 / np.pi)\n",
    "                    dip_ind.append(d* 180 / np.pi)\n",
    "\n",
    "\n",
    "        # append to lists\n",
    "        dip.append(dip_ind)\n",
    "        dip_direction.append(dip_dir_ind)\n",
    "        dip_score.append(dip_score_ind)\n",
    "\n",
    "    df['AC-dip'] = dip\n",
    "    df['AC-dip-direction'] = dip_direction\n",
    "    df['AC-dip-score'] = dip_score\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alhic2302 = calc_dip(alhic2302,'l')\n",
    "alhic2201 = calc_dip(alhic2201,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sph_to_cart(delta_deg, alpha_deg):\n",
    "    \"\"\"Convert (dip, azimuth) to unit vector [x,y,z].\"\"\"\n",
    "    d = np.deg2rad(delta_deg)\n",
    "    a = np.deg2rad(alpha_deg)\n",
    "    return np.column_stack([np.cos(d)*np.sin(a), np.cos(d)*np.cos(a), np.sin(d)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_spherical_median(vectors, weights, tol=1e-6, max_iter=1000):\n",
    "\n",
    "    \"\"\"Weighted Weiszfeld algorithm on the sphere.\"\"\"\n",
    "    m = np.average(vectors, axis=0, weights=weights)\n",
    "    m /= np.linalg.norm(m)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "\n",
    "        dots = np.clip(vectors.dot(m), -1, 1)\n",
    "        \n",
    "        angles = np.arccos(dots)\n",
    "        \n",
    "        if np.any(angles < tol):\n",
    "            print(\"Warning: some vectors are too close to the median, returning one of them.\")\n",
    "            return vectors[np.argmin(angles)]\n",
    "        w_ang = weights / angles\n",
    "        m_new = (w_ang[:, None] * vectors).sum(axis=0)\n",
    "        m_new /= np.linalg.norm(m_new)\n",
    "        if np.linalg.norm(m_new - m) < tol:\n",
    "            m = m_new\n",
    "            break\n",
    "        m = m_new\n",
    "\n",
    "    return m\n",
    "\n",
    "def weighted_spherical_mean(vectors, weights):\n",
    "    \"\"\"Weighted spherical mean.\"\"\"\n",
    "    m = np.average(vectors, axis=0, weights=weights)\n",
    "    m /= np.linalg.norm(m)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_median_dip(core, core_name):\n",
    "    \"\"\"\n",
    "    Calculate the median dip and azimuth of the planes in a core.\n",
    "    The function takes a dataframe with the angles and scores of the planes\n",
    "    and returns a dataframe with the median dip and azimuth of the planes.\n",
    "    \"\"\"\n",
    "    # create empty lists to store the results\n",
    "    dds = []\n",
    "    dips = []\n",
    "    depths = []\n",
    "    flags = []\n",
    "\n",
    "    for index, row in core.iterrows():\n",
    "\n",
    "        vectors = []\n",
    "        weights = []\n",
    "\n",
    "        # extract angles and scores\n",
    "        angles = row['AC-dip']\n",
    "        dir = row['AC-dip-direction']\n",
    "        scores = row['AC-dip-score']\n",
    "\n",
    "        # check if angles and scores are not NaN\n",
    "        if angles is not None and scores is not None:\n",
    "\n",
    "            for a,d,s in zip(angles, dir, scores):\n",
    "\n",
    "                # create a vector for each plane\n",
    "                vector = sph_to_cart(a, d)\n",
    "                vectors.append(vector[0])\n",
    "\n",
    "                # weights\n",
    "                weights.append(s)\n",
    "\n",
    "        # convert list of 3D vectors to numpy array\n",
    "        vectors = np.array(vectors)\n",
    "\n",
    "        # calculate the median vector\n",
    "        m = weighted_spherical_median(vectors,weights)\n",
    "\n",
    "        # compute the dip and azimuth of the median vector\n",
    "        dip = np.arcsin(m[2])#np.arctan2(np.linalg.norm(m[:2]), m[2])\n",
    "        dips.append(np.rad2deg(dip))\n",
    "        dd = np.arctan2(m[1], m[0])\n",
    "        dd = np.rad2deg(dd)\n",
    "\n",
    "        # define this function above calc_median_dip (e.g. in the cell before)\n",
    "        def angular_radius_for_weight_fraction(vectors, weights, center, fraction=0.5):\n",
    "            # compute angles between each vector and the center\n",
    "            dots = np.clip(vectors.dot(center), -1, 1)\n",
    "            angles = np.arccos(dots)\n",
    "            # sort by angle and accumulate weights\n",
    "            order = np.argsort(angles)\n",
    "            cumw = np.cumsum(np.array(weights)[order])\n",
    "            # find the index where cumulative weight reaches the target fraction\n",
    "            idx = np.searchsorted(cumw, fraction * cumw[-1])\n",
    "            return np.degrees(angles[order][idx])\n",
    "\n",
    "        # … inside calc_median_dip, at the placeholder:\n",
    "        radius = angular_radius_for_weight_fraction(vectors, weights, m, fraction=0.5)\n",
    "        if radius > 8:\n",
    "            flags.append(True)\n",
    "        else:\n",
    "            flags.append(False)\n",
    "        print(f\"Angular radius for {core_name} at section {row['section']}: {radius:.2f} degrees\")\n",
    "\n",
    "        # adjust the dip direction based on the core name\n",
    "        if core_name == 'alhic2201':\n",
    "            dd = dd-90\n",
    "        if dd < 0:\n",
    "            dd += 360\n",
    "        if dd>360:\n",
    "            dd -= 360\n",
    "            \n",
    "        # flip the dip direction\n",
    "        dd = 360 - dd\n",
    "        dds.append(dd)\n",
    "\n",
    "\n",
    "        # save the depth and core name from df\n",
    "        depths.append(row['depth'])\n",
    "\n",
    "    # create a dataframe with the results\n",
    "    results = pd.DataFrame({'depth': depths, 'dip': dips, 'dip_direction': dds, 'flag_uncertainty': flags})\n",
    "    \n",
    "    # save the results to a .csv file\n",
    "    results.to_csv(path_to_angles+core_name+'_median_dip.csv', index=False)\n",
    "\n",
    "    # add the results the original core dataframe\n",
    "    core['vector-dip-median'] = results['dip']\n",
    "    core['vector-dip-direction-median'] = results['dip_direction']\n",
    "    core['vector-flag-uncertainty'] = results['flag_uncertainty']\n",
    "\n",
    "    return results, core\n",
    "\n",
    "\n",
    "#for core,core_name in zip([alhic2302,alhic2201],['alhic2302','alhic2201']):\n",
    "\n",
    "alhic2302_vectorresults, alhic2302= calc_median_dip(alhic2302,'alhic2302')\n",
    "alhic2201_vectorresults, alhic2201 = calc_median_dip(alhic2201,'alhic2201')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dip Angle Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make figure\n",
    "fig, ax = plt.subplots(1,2,figsize=(7,6),dpi=300)\n",
    "\n",
    "# axis labels\n",
    "for a in ax:\n",
    "    a.set_ylabel('Depth (m)')\n",
    "    a.set_xlabel('Dip (°)')\n",
    "    a.set_xlim(0,90)\n",
    "    a.grid(True)\n",
    "ax[0].set_title('a) ALHIC2201')\n",
    "ax[1].set_title('b) ALHIC2302')\n",
    "ax[0].invert_yaxis()\n",
    "ax[1].invert_yaxis()\n",
    "ax[0].set_ylim(23,0)\n",
    "ax[1].set_ylim(47,0)\n",
    "\n",
    "def plot_dip(df,ax):\n",
    "    for index,row in df.iterrows():\n",
    "\n",
    "         # pull out values for this section\n",
    "        d = row['depth']\n",
    "        dip = np.array(row['AC-dip'])\n",
    "        scores = np.array(row['AC-dip-score'])\n",
    "\n",
    "        if not row['vector-flag-uncertainty']:\n",
    "\n",
    "            # check if row dip is nan\n",
    "            if np.isnan(dip).all():\n",
    "                ax.plot([0,90],[d,d],'r--',linewidth=0.5)\n",
    "            else:\n",
    "\n",
    "                # plot dip (individual points)\n",
    "                for i in range(len(dip)):\n",
    "                    ax.plot(dip[i],d,'k.',markersize=scores[i]*10)\n",
    "\n",
    "            # plot median dip\n",
    "            ax.plot(row['vector-dip-median'],row['depth'],'bo',markersize=5)\n",
    "\n",
    "        else:\n",
    "            # plot median dip\n",
    "            ax.plot(row['vector-dip-median'],row['depth'],'o',markersize=5,color='grey')\n",
    "\n",
    "            # check if row dip is nan\n",
    "            if np.isnan(dip).all():\n",
    "                ax.plot([0,90],[d,d],'r--',linewidth=0.5)\n",
    "            else:\n",
    "\n",
    "                # plot dip (individual points)\n",
    "                for i in range(len(dip)):\n",
    "                    ax.plot(dip[i], d, '.', color='grey', markersize=scores[i]*10)\n",
    "\n",
    "\n",
    "# add legend (to left subplot only)\n",
    "ax[1].plot([],[],'k.',markersize=2,label='Dip (size ∝ score)')\n",
    "ax[1].plot([],[],'b.',label='Median Dip')\n",
    "ax[1].plot([],[],'.',color='grey',linewidth=3,label='Median Dip (Spread>16°)')\n",
    "ax[1].plot([],[],'r--',linewidth=0.5,label='No Dip Estimate')\n",
    "ax[1].legend(loc='upper right', fontsize=8)\n",
    "\n",
    "plot_dip(alhic2201,ax[0])\n",
    "plot_dip(alhic2302,ax[1])\n",
    "\n",
    "# save figure\n",
    "fig.savefig(path_to_final_fig+'JOG-2024-0148.Figure7.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dip Direction plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alhic2201_breaks = [17.62,17.65,24.08]\n",
    "alhic2302_breaks = [10.37,19.73,20.39,24.28,30.72,39.53,40.47,41.39,42.7,44.57]\n",
    "\n",
    "# make figure\n",
    "fig, ax = plt.subplots(1,2,figsize=(7,6),dpi=300)\n",
    "\n",
    "# axis labels\n",
    "for a in ax:\n",
    "    a.set_ylabel('Depth (m)')\n",
    "    a.set_xlabel('Dip Direction (°)')\n",
    "    a.set_xlim(0,360)\n",
    "    a.grid(True)\n",
    "ax[0].set_title('a) ALHIC2201')\n",
    "ax[1].set_title('b) ALHIC2302')\n",
    "ax[0].invert_yaxis()\n",
    "ax[1].invert_yaxis()\n",
    "ax[0].set_ylim(23,0)\n",
    "ax[1].set_ylim(47,0)\n",
    "\n",
    "def plot_dd(df,ax,breaks,core):\n",
    "    for index,row in df.iterrows():\n",
    "\n",
    "         # pull out values for this section\n",
    "        d = row['depth']\n",
    "        dip = np.array(row['AC-dip'])\n",
    "        dd = np.array(row['AC-dip-direction'])\n",
    "        scores = np.array(row['AC-dip-score'])\n",
    "\n",
    "        # subtract 90 from dip direction if core is alhic2302\n",
    "        if core == 'alhic2302':\n",
    "            dd = dd - 90\n",
    "            # normalize each dd into [0,360)\n",
    "            dd = np.mod(dd, 360)\n",
    "\n",
    "\n",
    "\n",
    "        if not row['vector-flag-uncertainty']:\n",
    "\n",
    "            # check if row dip is nan\n",
    "            if np.isnan(dip).all():\n",
    "                ax.plot([0,360],[d,d],'r--',linewidth=0.5)\n",
    "            else:\n",
    "\n",
    "                # plot dip (individual points)\n",
    "                for i in range(len(dip)):\n",
    "                    ax.plot(dd[i],d,'k.',markersize=scores[i]*10)\n",
    "\n",
    "            # plot median dip\n",
    "            ax.plot(row['vector-dip-direction-median'],row['depth'],'bo',markersize=5)\n",
    "\n",
    "        else:\n",
    "            # plot median dip\n",
    "            ax.plot(row['vector-dip-direction-median'],row['depth'],'o',markersize=5,color='grey')\n",
    "\n",
    "            # check if row dip is nan\n",
    "            if np.isnan(dip).all():\n",
    "                ax.plot([0,360],[d,d],'r--',linewidth=0.5)\n",
    "            else:\n",
    "\n",
    "                # plot dip (individual points)\n",
    "                for i in range(len(dip)):\n",
    "                    ax.plot(dd[i], d, '.', color='grey', markersize=scores[i]*10)\n",
    "    \n",
    "# plot core breaks\n",
    "    for b in breaks:\n",
    "        ax.plot([0, 360], [b, b], 'k--')\n",
    "\n",
    "# add a legend (to left subplot only)\n",
    "ax[1].plot([],[],'k.',markersize=2,label='Dip Direction (size ∝ score)')\n",
    "ax[1].plot([],[],'b.',label='Median Dip Direction')\n",
    "ax[1].plot([],[],'.',color='grey',linewidth=3,label='Median Dip Direction (Spread>16°)')\n",
    "ax[1].plot([],[],'r--',linewidth=0.5,label='No Dip Direction Estimate')\n",
    "ax[1].plot([],[],'k--',linewidth=0.5,label='Core Breaks')\n",
    "ax[1].legend(loc='upper left', fontsize=8)\n",
    "        \n",
    "\n",
    "plot_dd(alhic2201,ax[0],alhic2201_breaks,'alhic2201')\n",
    "plot_dd(alhic2302,ax[1],alhic2302_breaks,'alhic2302')\n",
    "\n",
    "# save figure\n",
    "fig.savefig(path_to_final_fig+'JOG-2024-0148.Figure9.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dip Trend Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_trend(df):\n",
    "    \"\"\"\n",
    "    Perform a t-test on the slope of the trend of the dip angle in a core.\n",
    "    Uses only data where row['vector-flag-uncertainty'] is False.\n",
    "    Returns the slope, intercept, p-value, depth, and dip.\n",
    "    \"\"\"\n",
    "    # filter the dataframe to only include rows where vector-flag-uncertainty is False\n",
    "    df_filtered = df[df['vector-flag-uncertainty'] == False]\n",
    "    if df_filtered.empty:\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    # filter out rows where vector-dip-median is NaN\n",
    "    df_filtered = df_filtered[~df_filtered['vector-dip-median'].isna()]\n",
    "    if df_filtered.empty:\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    # extract the depth and dip values\n",
    "    depth = df_filtered['depth'].values\n",
    "    dip = df_filtered['vector-dip-median'].values\n",
    "    if len(depth) < 2 or len(dip) < 2:\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    # perform a linear regression on the depth and dip values\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(depth, dip)\n",
    "   \n",
    "    return slope, intercept, p_value, depth, dip\n",
    "\n",
    "# calculate t-test for alhic2201 and alhic2302\n",
    "alhic2201_slope, alhic2201_intercept, alhic2201_p_value, alhic2201_depth, alhic2201_dip = t_test_trend(alhic2201)\n",
    "alhic2302_slope, alhic2302_intercept, alhic2302_p_value, alhic2302_depth, alhic2302_dip = t_test_trend(alhic2302)\n",
    "\n",
    "# make figure\n",
    "fig, ax = plt.subplots(2,1,figsize=(7,6),dpi=300)\n",
    "for a in ax:\n",
    "    a.set_xlabel('Depth (m)')\n",
    "    a.set_ylabel('Dip (°)')\n",
    "    a.set_xlim(0,90)\n",
    "    a.grid(True)\n",
    "ax[0].set_title('a) ALHIC2201')\n",
    "ax[1].set_title('b) ALHIC2302')\n",
    "ax[0].set_xlim(0,28)\n",
    "ax[1].set_xlim(8,47)\n",
    "\n",
    "# plot the data points (make them grey if uncertainty is True)\n",
    "def plot_trend(df,ax):\n",
    "    goodflag = True\n",
    "    badflag = True\n",
    "    for index,row in df.iterrows():\n",
    "\n",
    "        # pull out values for this section\n",
    "        d = row['depth']\n",
    "        dip = row['vector-dip-median']\n",
    "        flag = row['vector-flag-uncertainty']\n",
    "\n",
    "        if not flag:\n",
    "            ax.plot(d,dip,'b.',markersize=4,label='Median Dip' if goodflag else \"\")\n",
    "            goodflag = False\n",
    "        else:\n",
    "            ax.plot(d,dip,'.',color='grey',markersize=4,label='Median Dip (Spread>16°)' if badflag else \"\")\n",
    "            badflag = False\n",
    "\n",
    "    # plot the trend line\n",
    "    slope, intercept, p_value, depth, dip = t_test_trend(df)\n",
    "    if slope is not None:\n",
    "        label = f'Trendline (Slope: {slope:.2f}, \\n Pval = {p_value:.3f})'\n",
    "        ax.plot(depth, slope*depth + intercept, 'k--', linewidth=1,label=label)\n",
    "        # ax.text(0.05, 0.95, f'p-value: {p_value:.3f}', transform=ax.transAxes, fontsize=8,\n",
    "        #         verticalalignment='top', bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "    ax.legend(loc='lower left')\n",
    "\n",
    "plot_trend(alhic2201,ax[0])\n",
    "plot_trend(alhic2302,ax[1])\n",
    "\n",
    "# set tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# save figure\n",
    "fig.savefig(path_to_final_fig+'JOG-2024-0148.Figure8.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find average dip in ALHIC2201 above the first core break\n",
    "alhic2201_above_break = alhic2201[alhic2201['depth'] < alhic2201_breaks[0]]\n",
    "\n",
    "# filter for where the flag is False\n",
    "alhic2201_above_break = alhic2201_above_break[alhic2201_above_break['vector-flag-uncertainty'] == False]\n",
    "\n",
    "\n",
    "average_dip_direction = alhic2201_above_break['vector-dip-direction-median'].mean()\n",
    "std_dip_direction = alhic2201_above_break['vector-dip-direction-median'].std()\n",
    "print(\"Average Dip Direction above the first orientation lost is \"+str(round(average_dip_direction,1)))\n",
    "print(\"Standard Deviation of Dip Direction above the first orientation lost is \"+str(round(std_dip_direction,1)))\n",
    "\n",
    "#Move into degrees east framework\n",
    "o_line_azimuth = 59\n",
    "dip_azimuth = o_line_azimuth - average_dip_direction\n",
    "\n",
    "print(\"ALHIC2201 Dip azimuth is \"+str(round((dip_azimuth+360)%360,1))+\" degrees E of N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report total number of sections and number of “good” (vector-flag-uncertainty=False) sections\n",
    "print(f\"Total number of sections in alhic2201: {len(alhic2201)}\")\n",
    "print(f\"Total number of sections in alhic2201 where dip is nan: {len(alhic2201[alhic2201['vector-dip-median'].isna()])}\")\n",
    "n_good_2201 = ((~alhic2201['vector-flag-uncertainty']) & (~alhic2201['vector-dip-median'].isna())).sum()\n",
    "print(f\"Number of good sections in alhic2201: {n_good_2201}\")\n",
    "\n",
    "# duplicate the above for alhic2302\n",
    "print(f\"Total number of sections in alhic2302: {len(alhic2302)}\")\n",
    "print(f\"Total number of sections in alhic2302 where dip is nan: {len(alhic2302[alhic2302['vector-dip-median'].isna()])}\")\n",
    "n_good_2302 = ((~alhic2302['vector-flag-uncertainty']) & (~alhic2302['vector-dip-median'].isna())).sum()\n",
    "print(f\"Number of good sections in alhic2302: {n_good_2302}\")\n",
    "\n",
    "# Median and standard deviation of the median dip for good sections\n",
    "median_dip_2201 = alhic2201.loc[~alhic2201['vector-flag-uncertainty'], 'vector-dip-median'].mean()\n",
    "std_dip_2201    = alhic2201.loc[~alhic2201['vector-flag-uncertainty'], 'vector-dip-median'].std()\n",
    "median_dip_2302 = alhic2302.loc[~alhic2302['vector-flag-uncertainty'], 'vector-dip-median'].mean()\n",
    "std_dip_2302    = alhic2302.loc[~alhic2302['vector-flag-uncertainty'], 'vector-dip-median'].std()\n",
    "\n",
    "print(f\"alhic2201 median dip (good): {median_dip_2201:.2f}° ± {std_dip_2201:.2f}°\")\n",
    "print(f\"alhic2302 median dip (good): {median_dip_2302:.2f}° ± {std_dip_2302:.2f}°\")\n",
    "\n",
    "# combined percentage of good sections\n",
    "total_sections      = len(alhic2201) + len(alhic2302)\n",
    "total_good_sections = n_good_2201 + n_good_2302\n",
    "pct_good = total_good_sections / total_sections * 100\n",
    "print(f\"Percentage of good sections overall: {pct_good:.1f}%\")\n",
    "\n",
    "# percentage of nan dips in alhic2201 and alhic2302 and combined\n",
    "pct_nan_2201 = len(alhic2201[alhic2201['vector-dip-median'].isna()]) / len(alhic2201) * 100\n",
    "pct_nan_2302 = len(alhic2302[alhic2302['vector-dip-median'].isna()]) / len(alhic2302) * 100\n",
    "pct_nan_combined = (len(alhic2201[alhic2201['vector-dip-median'].isna()]) + len(alhic2302[alhic2302['vector-dip-median'].isna()])) / total_sections * 100\n",
    "print(f\"Percentage of NaN dips in alhic2201: {pct_nan_2201:.1f}%\")\n",
    "print(f\"Percentage of NaN dips in alhic2302: {pct_nan_2302:.1f}%\")\n",
    "print(f\"Percentage of NaN dips overall: {pct_nan_combined:.1f}%\")\n",
    "\n",
    "# percentage of sections with vector-flag-uncertainty=True\n",
    "pct_uncertainty_2201 = alhic2201['vector-flag-uncertainty'].mean() * 100\n",
    "pct_uncertainty_2302 = alhic2302['vector-flag-uncertainty'].mean() * 100\n",
    "pct_uncertainty_combined = (alhic2201['vector-flag-uncertainty'].sum() + alhic2302['vector-flag-uncertainty'].sum()) / total_sections * 100\n",
    "print(f\"Percentage of sections with vector-flag-uncertainty=True in alhic2201: {pct_uncertainty_2201:.1f}%\")\n",
    "print(f\"Percentage of sections with vector-flag-uncertainty=True in alhic2302: {pct_uncertainty_2302:.1f}%\")\n",
    "print(f\"Percentage of sections with vector-flag-uncertainty=True overall: {pct_uncertainty_combined:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
